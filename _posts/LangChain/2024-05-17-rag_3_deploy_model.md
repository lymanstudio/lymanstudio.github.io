---
layout: single
title:  "RAG ì‹¤ìŠµ 3. PDFíŒŒì¼ê³¼ ëŒ€í™”í•˜ê¸°(í•˜: ìµœì¢… ëª¨ë¸ êµ¬ì„± ë° Streamlitìœ¼ë¡œ ë°°í¬í•˜ê¸°)"
classes: wide
categories: LangChain
tags: [LangChain, RAG, Streamlit]
---

[ì´ì „ í¬ìŠ¤íŠ¸](https://lymanstudio.github.io/langchain/rag_2_paper_cleansing/)ì—ì„œ loadëœ Documentë“¤ì˜ ë‚´ìš©ì„ ì •ì œí•˜ê¸° ìœ„í•´ í´ë Œì§• ì²´ì¸ì„ êµ¬ì„±í•˜ê³  ì ìš©í•˜ì—¬ ê·¸ ê²°ê³¼ë¥¼ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ chunkingí•˜ì˜€ë‹¤.  ê°„ë‹¨í•œ TextSpliterë¥¼ ì‚¬ìš©í•˜ê¸° ë³´ë‹¨ ë¬¸ì¥ ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•´ ê·¸ê²ƒì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ë“¤ì˜ ë¶€ë¶„ ì§‘í•©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì¥ë“¤ì„ ë¬¶ì–´ í•˜ë‚˜ì˜ Documentë¡œ êµ¬ì„±í•˜ì˜€ë‹¤.

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„  ì•ì„  í¬ìŠ¤íŠ¸ë“¤ì—ì„œ ì‚¬ìš©í•œ ê¸°ëŠ¥ë“¤ê³¼ ê¸°íƒ€ í•„ìš”í•œ ê¸°ëŠ¥ë“¤ì„ í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì™„ì „í•œ ì‹œìŠ¤í…œìœ¼ë¡œ êµ¬ì„±í•˜ê³  streamlitìœ¼ë¡œ ì›¹ ê¸°ë°˜ ì•±ì„ ë§Œë“¤ì–´ ë°°í¬ê¹Œì§€ í•˜ëŠ” ê³¼ì •ì„ ì†Œê°œí•  ì˜ˆì •ì´ë‹¤.

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„  ë‹¤ë¤„ë³¼ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

* íƒ€ê²Ÿ ì„œë¹„ìŠ¤ëŠ” ì•„ë˜ì™€ ê°™ì€ ë‘ê°€ì§€ í° ë‹¨ê³„ë¡œ êµ¬ì„±ëœë‹¤.
  * ë…¼ë¬¸ ì¤€ë¹„ ë‹¨ê³„: ë…¼ë¬¸ ì—…ë¡œë“œ â¡ ì²´ì¸ì„ í†µí•œ í…ìŠ¤íŠ¸ í´ë Œì§• â¡ ì˜ë¯¸ì ìœ¼ë¡œ ë¬¶ì´ê²Œ ë¬¸ì¥ chunking â¡ ë²¡í„° DBë¡œ ì €ì¥
  * ì§ˆì˜ë¬¸ë‹µ ë‹¨ê³„: ì‚¬ìš©ì ì§ˆì˜ â¡ Qì²´ì¸ì„ í†µí•œ ì§ˆë¬¸ í¸ì§‘ â¡ Aì²´ì¸ì„ í†µí•œ í¸ì§‘ëœ ì§ˆë¬¸ì— ëŒ€í•œ ë‹¨ë³€ ìƒì„± â¡ ì‚¬ìš©ìì—ê²Œ ìµœì¢… ë‹µë³€ ì „ë‹¬
* ìœ„ ë‹¨ê³„ë¥¼ êµ¬ì„±í•˜ëŠ” ì¢…í•©ì ì¸ íŒŒì´ì¬ íŒŒì¼ë“¤ì„ ì •ë¦¬í•˜ê³  mainì—ì„œ ìƒí™©ì— ë§ëŠ” ë¶„ê¸°ë¡œ ì‹œìŠ¤í…œì„ ì¡°ë¦½í•œë‹¤.
* ì¡°ë¦½ëœ ì½”ë“œë¥¼ streamlitìœ¼ë¡œ ê°ì‹¸ ì•±ì„ êµ¬ì„±í•œë‹¤.

---



# Step 5. ì²´ì¸ ë¶„ë¦¬

ìš°ì„  ì²´ì¸ì„ ë¶„ë¦¬í•˜ì—¬ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ë”ìš± ìœ ì—°í•˜ê³  íƒ„ë ¥ì ìœ¼ë¡œ ëŒ€ì²˜ê°€ ê°€ëŠ¥í•˜ê²Œ êµ¬ì„±í•´ë³´ì.

## Paper Clean Chain

ì²«ë²ˆì§¸ ì²´ì¸ì€ ì—…ë¡œë“œëœ ë…¼ë¬¸ íŒŒì¼ì„ loaderë¡œ ë¶ˆëŸ¬ì™€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í¸ì§‘í•´ì£¼ëŠ” Paper Clean Chainì´ë‹¤.

ì´ì „ í¬ìŠ¤íŠ¸ì—ì„œ ì†Œê°œí•œ ê·¸ëŒ€ë¡œì´ë©° ë‹¤ìŒê³¼ ê°™ì´ í•¨ìˆ˜ë¡œ êµ¬ì„±í–ˆë‹¤.

```python
def paper_clean_chain():
    prompt = PromptTemplate.from_template("""
    You are an editor who is an expert on editing thesis papers into rich and redundant-erased writings. Your job is to edit PAPER.
    If the client gives you PAPER(a part of the thesis paper) with PRV_PAGE(the summary of the previous page).
    To make an edited version of PAPER, you have to keep the following rules.
    1. Erase all the additional information that is not directly related to the idea and content of the paper, such as the name of a journal, page numbers, and so on.
    In most cases, the additional information is located in the first or the last part of PAPER. 
    2. Erase all the reference/citation marks of numbers in the middle of PAPER.
    3. Edit PAPER in a rich manner and should contain all the ideas and content. Do not discard any content. 
    4. It has to be related and successive to the content of PRV_PAGE. But should not repeatedly have the PRV_PAGE content.
    5. Note that successive pages are waiting to be edited, so the result should not end with the feeling that it is the last document.
    6. Do not conclude at the end of the current editing, unless PAPER only contains references(imply that current PAPER is the end of the thesis). 

    ## PRV_PAGE: {prv_page}

    ## PAPER: {content} 
    """
    )

    model = ChatOpenAI(model = 'gpt-3.5-turbo')

    return prompt | model | StrOutputParser()
```



## Q Chain

ì‚¬ìš©ìëŠ” ìì‹ ì´ ì—…ë¡œë“œ í•œ ë…¼ë¬¸ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•  ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ì´ ì§ˆë¬¸ì€ ëª¨ë¸ì— ë“¤ì–´ê°€ê¸° ì „ í¸ì§‘ë˜ì•¼í•˜ëŠ”ë° ê·¸ ì´ìœ ëŠ” í¬ê²Œ

- ì‚¬ëŒë§ˆë‹¤ ì§ˆë¬¸ ìŠ¤íƒ€ì¼ì€ ë§¤ìš° ë‹¤ë¥¼ ìˆ˜ ìˆê³  ë•Œì— ë”°ë¼ì„  ê°„ê²°í•˜ì§€ ì•Šê³  í•„ìš” ì—†ëŠ” ë§ì´ ë§ë¶™ì—¬ì ¸ ìˆëŠ” ê²½ìš°ê°€ ë§ë‹¤.
- ìš°ë¦¬ì˜ ë…¼ë¬¸ì€ (ëŒ€ë¶€ë¶„) ì˜ì–´ë¡œ êµ¬ì„±ë¼ìˆê¸°ì— ì§ˆë¬¸ë„ ê°„ê²°í•˜ê³  ëª…í™•í•œ ì˜ì–´ë¡œ ë“¤ì–´ê°€ì•¼ í•œë‹¤.
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ì§ˆë¬¸ì— ì‚¬ìš©ëœ ì–¸ì–´ë¡œ êµ¬ì„±ë¼ì•¼ í•œë‹¤.

ìœ„ì˜ ì´ìœ ë¡œ ì‚¬ìš©ì ììœ ë¶„ë°©í•œ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ì“°ì—¬ì§„ ê¹”ë”í•œ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ì£¼ë©° ì›ë˜ ì§ˆë¬¸ì˜ ì–¸ì–´ë„ ì•Œë ¤ì£¼ëŠ” ì²´ì¸ì„ Q(question) chainì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ êµ¬ì„±í–ˆë‹¤.

```python
def q_chain(llm) -> str:
    class response(BaseModel):
        processed_query: str = Field(description="Processed version of user input query")
        language: str = Field(description="The language that the user spoken")
    
    structured_parser = JsonOutputParser(pydantic_object=response)
    
    processing_prompt = PromptTemplate.from_template("""
    Your job is translating and converting a user input query into an easy-to-understand LLM model input query regarding CONTEXT.
    The CONTEXT is a set of metadata for a thesis paper consisting of the title, abstract, and other additional information. Its structure is a sequence of pairs of keys and values.
    
    Here is the sequence of your job:
    1. If needed(using different languages), translate the user input QUERY into the language that CONTEXT is written.
    2. Depending of the CONTEXT values, convert the user input QUERY into a question that a QA LLM model for the CONTEXT paper would be easy to comprehend
    3. OUTPUT is json format object that holds converted output and language that user speaks in QUERY.
        The converted output should go to "processed_query" key and the language go to "language" key.
    # CONTEXT:
    {context}

    # QUERY:
    {question}

    # OUTPUT:          
    """)

    return (
        {
            "context": itemgetter('context') | RunnablePassthrough(),
            "question": itemgetter('question') | RunnablePassthrough()
        }
        | processing_prompt
        | llm
        | structured_parser
    )

```

### í”„ë¡¬í”„íŠ¸

ìš°ì„  í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì. í”„ë¡¬í”„íŠ¸ëŠ” ì´ì „ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ìƒí™© ì„¤ëª…, í–‰ë™ ì§€ì¹¨, ì…ë ¥ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. 

- ìƒí™©ì€ ê°„ë‹¨í•˜ê²Œ ìœ ì €ì˜ ì§ˆì˜ë¬¸ì„ CONTEXTë¥¼ ê°ì•ˆí•´ì„œ LLMì´ ì˜ ì´í•´í•  ìˆ˜ ìˆê²Œë” CONTEXTê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¡œ ë°”ê¿”ì£¼ë¼ëŠ” ìš”êµ¬ì‚¬í•­ê³¼ CONTEXTì— ëŒ€í•œ ë°°ê²½ ì„¤ëª…ìœ¼ë¡œ êµ¬ì„±í–ˆë‹¤.
- í–‰ë™ ì§€ì¹¨ì€ ì£¼ëª©ì ê³¼ OUTPUT í˜•íƒœë¥¼ íŠ¹ì • í˜•íƒœë¡œ ê³ ì • ì‹œì¼œ ë‚´ë°·ì–´ ë‹¬ë¼ê³  ìš”êµ¬í•˜ëŠ” ë‚´ìš©ì´ë‹¤.
- ì…ë ¥ ë°›ì„ íŒŒë¼ë¯¸í„°ëŠ” CONTEXT: {`context`}, QUERY: {`question`}ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. ì´ ë‘ê°œì˜ íŒŒë¼ë¯¸í„°ëŠ” ì‹¤í–‰ë‹¨ê³„ì—ì„œ RunnablePassthroughë¡œ ë“¤ì–´ê°„ë‹¤.

### ì…ì¶œë ¥

ë‹¤ìŒìœ¼ë¡œ ì•Œì•„ë³¼ q ì²´ì¸ì˜ íŠ¹ì§•ì€ ì…ë ¥ê³¼ ì¶œë ¥ì˜ êµ¬ì¡°ì´ë‹¤.

> ì…ë ¥: ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆì˜ë¬¸ê³¼ ë…¼ë¬¸ì˜ ë©”íƒ€ ë°ì´í„°

ìš°ì„  ì…ë ¥ì€ ë‹¹ì—°í•˜ê²Œë„ ì‚¬ìš©ìì˜ ì§ˆì˜ë¬¸ì´ ëœë‹¤. ìš°ë¦¬ì˜ ëª©ì ì€ ì§ˆì˜ë¬¸ì„ ë…¼ë¬¸ì˜ ëª©ì ì— ë§ëŠ” ì§ˆì˜ë¬¸ìœ¼ë¡œ í¸ì§‘í•´ì£¼ëŠ” ê²ƒì´ê¸°ì— ì²´ì¸ì˜ contextì— ì¶”ê°€ë¡œ ë…¼ë¬¸ì˜ ë©”íƒ€ ë°ì´í„°ë¥¼ ë„£ì–´ì£¼ì—ˆë‹¤.

LCELì—ì„œ í”„ë¡¬í”„íŠ¸ì˜ ì…ë ¥ìœ¼ë¡œ ë³µìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì£¼ê¸° ìœ„í•´ 

> ì¶œë ¥: í¸ì§‘ëœ ì˜ì–´ë¡œ ëœ ì§ˆì˜ë¬¸(processed_query)ê³¼ ì›ë˜ ì–¸ì–´(language)ë¡œ êµ¬ì„±ëœ JSON ë°ì´í„°

llm ëª¨ë¸ì´ ì¶œë ¥ì„ ë¯¸ë¦¬ ì •í•´ë†“ì€ êµ¬ì¡°ë¡œ ë‚´ë±‰ê²Œ í•˜ê¸° ìœ„í•´ pydantic í´ë˜ìŠ¤ì˜ BaseModelì„ ì‚¬ìš©í•´ JSON êµ¬ì¡°ë¡œ ì¶œë ¥í•˜ê²Œ êµ¬ì„±í–ˆë‹¤.
```python
class response(BaseModel):
        processed_query: str = Field(description="Processed version of user input query")
        language: str = Field(description="The language that the user spoken")

structured_parser = JsonOutputParser(pydantic_object=response)
```

ìœ„ ì²˜ëŸ¼ `response`ë¼ëŠ” í´ë˜ìŠ¤ë¥¼ ê°„ë‹¨í•˜ê²Œ ì •ì˜í•´ì¤€ ë’¤ chainì˜ ê°€ì¥ ë§ˆì§€ë§‰ ì¶œë ¥ íŒŒì„œë¡œ ì •ì˜í•œ `response`ì˜ í˜•ì‹ìœ¼ë¡œ ë‚´ë±‰ëŠ” JsonOutputParser ê°ì²´ë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤.

### Chain êµ¬ì„±

```python
{
    "context": itemgetter('context') | RunnablePassthrough(),
    "question": itemgetter('question') | RunnablePassthrough()
}
| processing_prompt
| llm
| structured_parser
```

- ì…ë ¥ìœ¼ë¡œ ë‘ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì•„ì•¼ í•˜ê¸°ì— ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” Dictí˜•íƒœì˜ ì¸í’‹ì—ì„œ keyì— ë”°ë¥¸ ê° valueì„ RunnablePassthroughë¥¼ ì‚¬ìš©í•´ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ì¤€ë‹¤.

- êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” llmì„ ê±°ì¹œë‹¤.
- llmì„ í†µí•´ ë‚˜ì˜¨ ê²°ê³¼ëŠ” `structured_parser`ë¡œ ë“¤ì–´ê°€ ë¯¸ë¦¬ ì •ì˜í•œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ëœë‹¤.



## A Chain

ë§ˆì§€ë§‰ ì²´ì¸ì€ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•´ì¤„ A(answer) Chainì´ë‹¤. ìš°ì„  êµ¬ì„±ì„ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

```python
def a_chain(vector_store, retriever, llm):

    prompt = PromptTemplate.from_template("""
    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë…¼ë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ í™œìš©í•´ ì‚¬ìš©ìê°€ ë˜ì§€ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€ì„ í•´ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ëŠ” ë…¼ë¬¸ì˜ ì œëª©(TITLE), ë…¼ë¬¸ì˜ ì´ˆë¡(ABSTRACT), ì§ˆë¬¸ì— ëŒ€í•œ ì„¸ë¶€ ì •ë³´ë¥¼ ë‹´ì€ ì»¨í…ìŠ¤íŠ¸(CONTEXT), ê·¸ë¦¬ê³  ë…¼ë¬¸ì— ëŒ€í•œ ê¸°íƒ€ ì •ë³´(ADDITIONAL_INFO)ì…ë‹ˆë‹¤.
    ë‹µë³€ì€ CONTEXTë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ë˜ CONTEXTì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì€ ë¬´ì‹œí•˜ê³  ë…¼ë¬¸ì˜ ì œëª©ê³¼ ì´ˆë¡ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì•¼í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ CONTEXTë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° "ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•´ ì£¼ì„¸ìš”.
    ë‹µë³€ì˜ ì–¸ì–´ëŠ” {language}ë¡œ í•´ì£¼ì„¸ìš”.                          
    # TITLE:
    {title}

    # ABSTRACT:
    {abstract}
                                        
    # ADDITIONAL_INFO:
    {add_info}                

    # CONTEXT:
    {context}

    # ì§ˆë¬¸:
    {question}

    # ë‹µë³€:
    """
    )

    def get_metadata(key:str) -> str: # ë²¡í„° ìŠ¤í† ì–´ì˜ ì²« Documentì˜ metadata ë”•ì…”ë„ˆë¦¬ì—ì„œ keyì— ë§ëŠ” valueë¥¼ ë±‰ì–´ì£¼ëŠ” í•¨ìˆ˜
        return next(iter(vector_store.docstore._dict.values())).metadata[key]

    def get_metadata_otherthen(exclude_keys:List[str]) -> str: # ë²¡í„° ìŠ¤í† ì–´ì˜ ì²« Documentì˜ metadata ë”•ì…”ë„ˆë¦¬ì—ì„œ ì¸ìë¡œ ë°›ì€ keyë“¤ì„ ì œì™¸í•œ ë‹¤ë¥¸ keyë“¤ê³¼ value ìŒì„ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ë±‰ì–´ì£¼ëŠ” í•¨ìˆ˜
        return "\n".join(f"{k} : {v}" for k, v in next(iter(vector_store.docstore._dict.values())).metadata.items() if k not in (exclude_keys))

    def concat_docs(docs:List[Document]) -> str: # retrieverê°€ ë°˜í™˜í•œ ëª¨ë“  Documentë“¤ì˜ page_contentë¥¼ í•˜ë‚˜ì˜ ë‹¨ì¼ stringìœ¼ë¡œ ë¶™ì—¬ì£¼ëŠ” í•¨ìˆ˜
        return "".join(doc.page_content for doc in docs)

    return (
        {
            "title": itemgetter('title') | RunnableLambda(get_metadata), # ì…ë ¥ ë°›ì€ ë°ì´í„° ì¤‘ titleì„ get_metadataí•¨ìˆ˜ì˜ ì¸ìë¡œ ë„£ê³  ë°˜í™˜ ë°›ì€ value ê°’ì„ titleë¡œ promptì— ë„£ì–´ì¤Œ
            "abstract": itemgetter('abstract') | RunnableLambda(get_metadata),
            "add_info": itemgetter('add_info') | RunnableLambda(get_metadata_otherthen),
            "context": itemgetter('question') | retriever | concat_docs, # ì…ë ¥ ë°›ì€ ë°ì´í„° ì¤‘ questionì„ retrieverì— ì „ë‹¬, ë°˜í™˜ ë°›ì€ kê°œì˜ Documentë“¤ì„ concat_docs í•¨ìˆ˜ì— ì „ë‹¬, ë‚´ìš©ë“¤ì´ concatëœ í•˜ë‚˜ì˜ ìŠ¤íŠ¸ë§ì„ contextë¡œ promptì— ë„£ì–´ì¤Œ
            "question": itemgetter('question') | RunnablePassthrough(), # ì…ë ¥ ë°›ì€ ë°ì´í„° ì¤‘ questionì„ ê·¸ëƒ¥ ë°›ì€ í˜•íƒœ ê·¸ëŒ€ë¡œ ì „ë‹¬, questionìœ¼ë¡œ promptì— ë„£ì–´ì¤Œ
            "language": itemgetter('language') | RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
    )
```

### í”„ë¡¬í”„íŠ¸

í”„ë¡¬í”„íŠ¸ëŠ” Q chainê³¼ ë‹¬ë¦¬ ê°„ë‹¨í•˜ê²Œ í•œêµ­ì–´ë¡œ ì…ë ¥í–ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ë“¤ì„ ì¢…í•©í•´ ë‹µë³€ì„ ë‚´ì£¼ë˜ ì…ë ¥ë°›ì€ language ë¡œ ì¨ë‹¬ë¼ëŠ” ê°„ë‹¨í•œ ë‚´ìš©ì´ë‹¤.

### ì…ì¶œë ¥

A Chainì€ ë§ˆì§€ë§‰ ë‹¨ê³„ì¸ ë§Œí¼ ë§ì€ ì •ë³´ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤. ì…ë ¥ì˜ ì¢…ë¥˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì´ 6ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì•„ì•¼ í•œë‹¤.

- ì•ì„œ êµ¬ì„±í•œ Q chainì—ì„œ ìƒì„±ëœ ì§ˆë¬¸:{`question`}, ì–¸ì–´:{`language`} ì •ë³´
- ì§ˆë¬¸ì— ë‹µë³€ì„ ì¤„ ìˆ˜ ìˆëŠ” Documentë“¤ë¡œ êµ¬ì„±ëœ CONTEXT:{`context`}
- ë‹µë³€ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ë©”íƒ€ ë°ì´í„°(TITLE:{`title`}, ABSTRACT(ì´ˆë¡):{`abstract`}, ADDITIONAL_INFO(ê¸°íƒ€ ë¶€ê°€ ì •ë³´):{`add_info`}

ì¶œë ¥ì€ ë§ˆì§€ë§‰ ë‹µë³€ì´ê¸°ì— ë‹¨ìˆœí•œ ìŠ¤íŠ¸ë§ì´ë‹¤. ë”°ë¼ì„œ ì²´ì¸ì˜ ë§ˆì§€ë§‰ íŒŒì„œëŠ” `StrOutputParser()`ë¥¼ ì‚¬ìš©í–ˆë‹¤.

### Chain êµ¬ì„±

í”„ë¡¬í”„íŠ¸ë¡œ ë“¤ì–´ê°€ëŠ” íŒŒë¼ë¯¸í„°ê°€ 6ê°œë¡œ ë§ê¸°ì— ê°ê°ì— ëŒ€í•´ ì²´ì¸ì— ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ Dictionary ê°ì²´ì—ì„œ ì•Œë§ì€ valueë“¤ì„ í• ë‹¹í•´ì¤€ë‹¤.

-  `question`, `language`ëŠ” ì•ì„  q chainì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ RunnablePassthroughë¥¼ í†µí•´ ê·¸ëŒ€ë¡œ ì „ë‹¬ëœë‹¤.
- `title`, `abstract`, `add_info`ëŠ” ë©”íƒ€ ë°ì´í„°ì—ì„œ ê°€ì ¸ì™€ì•¼í•˜ëŠ” ê°’ë“¤ì´ë‹¤. ë‹¨ìˆœíˆ RunnablePassthroughë¡œ ë„£ì–´ì¤„ ìˆ˜ ì—†ìœ¼ë©° ê° get_metadata, get_metadata_otherthenì´ë¼ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•´ RunnableLambdaë¥¼ í†µí•´ ëŒë‹¤í•¨ìˆ˜ì²˜ëŸ¼ ë™ì‘í•˜ê²Œ í•œ í›„ ì…ë ¥ Dictì˜ ê° keyì— í•´ë‹¹í•˜ëŠ” valueë“¤ì„ ì…ë ¥í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì˜ ê° íŒŒë¼ë¯¸í„°ë¡œ ë„£ì–´ì¤€ë‹¤.
- `context`ëŠ” ê¸° êµ¬ì„±ëœ retrieverë¥¼ í†µí•´ ë°˜í™˜ëœ ê°’ì„ ë„£ì–´ì¤˜ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ ì‘ì€ ì²´ì¸ì´ êµ¬ì„±ëë‹¤.
  - ì…ë ¥ Dictì˜ `question` keyì— í•´ë‹¹í•˜ëŠ” value â¡ retrieverë¡œ ë°˜í™˜ëœ Docë“¤ â¡ concat_docsë¥¼ í†µí•´ í…ìŠ¤íŠ¸ë“¤ì„ ëª¨ë‘ í•˜ë‚˜ì˜ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ì´ì–´ì¤Œ â¡ ê²°ê³¼ë¥¼ `context`ì— ë„£ì–´ì¤Œ

ì´í›„ promptì™€ llmì„ í†µí•´ ê²°ê³¼ë¥¼ êµ¬í•œ ë’¤ ê²°ê³¼ë¥¼ ë‹¨ìˆœ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ì¶œë ¥í•œë‹¤.



# Step 6. ì½”ë“œ ì •ë¦¬

ìœ„ì—ì„œ ì •ì˜í•œ chainë“¤ì„ í¬í•¨í•˜ì—¬ ìš°ë¦¬ê°€ ê°€ì§„ í•¨ìˆ˜/ê¸°ëŠ¥ë“¤ì„ ìš©ë„ì— ë”°ë¼ êµ¬ë¶„í•´ ê°ì íŒŒì¼ë¡œ êµ¬ì„±í•´ë³´ì.

### RAGì— ì‚¬ìš©ë˜ëŠ” ì²´ì¸ë“¤ => `rag_chains.py`

- Cleansing Chain

- Q chain

- A chain


### ê¸°íƒ€ ê¸°ëŠ¥ => `utils.py`

- PDF ë¡œë”©(load_pdf)
- ë¬¸ì„œ í´ë Œì§•(cleansing chain ì´ìš©, clean_paper)
- ë¬¸ì„œ Chunking(chunk_paper)
- Document ì²´í‚¹(check_docs_str)

### ë²¡í„° ìŠ¤í† ì–´ ìƒì„±, ë¡œë”© ê´€ë ¨ => `vectorstore.py`

- í˜„ì¬ ë…¼ë¬¸ì— ëŒ€í•œ ë²¡í„° ìŠ¤í† ì–´ê°€ ê¸° êµ¬ì¶•ëœ ê²½ìš° ë¡œë”©(load_store)
- ì‹ ê·œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±(create_store)

### ë¡œì»¬ ì €ì¥ ëŒ€ìƒ => ê°ì ê²½ë¡œ ìƒì„±

- ë°ì´í„°: ë…¼ë¬¸ PDFë“±
- ë²¡í„° ìŠ¤í† ì–´: ë…¼ë¬¸ì„ í†µí•´ êµ¬ì„±ëœ vectorStoreë“¤

### ì „ì²´ ì‹¤í–‰ íŒŒì¼ => `main.py`

- Streamlitì„ ì‚¬ìš©í•œ ì‹œí€€ìŠ¤ì— ë”°ë¥¸ ì‹¤í–‰ ì½”ë“œ
- API key ì²´í¬ í•¨ìˆ˜(is_api_key_valid)
- ì¿¼ë¦¬ ìƒì„± í•¨ìˆ˜(query)

ê²°ê³¼ëŠ” Github Repo([ğŸ”—](https://github.com/lymanstudio/lymanstudio.github.io))ì— ì˜¬ë¼ê°€ ìˆëŠ” ì½”ë“œë¥¼ ì°¸ê³ í•˜ë©´ ëœë‹¤.
