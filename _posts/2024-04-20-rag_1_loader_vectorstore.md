ì´ë²ˆ í”„ë¡œì íŠ¸ëŠ” RAG(Retrieval-Augmented Generation)ë¥¼ ì‚¬ìš©í•˜ëŠ” ì‹¤ìŠµìœ¼ë¡œ ìœ ì €ê°€ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ëª¨ë¸ì´ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ìˆ™ì§€í•˜ê²Œ ë§Œë“  ë’¤ ìœ ì €ì˜ ìì—°ì–´ ì§ˆë¬¸ì— ëŒ€í•´ PDF ë‚´ìš©ì„ ê·¼ê±°ë¡œ ë‹µë³€í•´ì£¼ëŠ” ì±—ë´‡ì„ ë§Œë“¤ì–´ ë³´ëŠ” ê²ƒì´ë‹¤.

ì´ë¥¼ ìœ„í•´ ìš°ë¦¬ê°€ í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

- PDF loading: ìœ ì €ê°€ ì—…ë¡œë“œí•˜ëŠ” PDFë¥¼ ì½ì–´ì™€ í•„ìš”í•˜ë‹¤ë©´ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆˆ ë“¸ ê° ë¶€ë¶„ë“¤ì„ ëª¨ë¸ì´ ì•Œì•„ë“¤ì„ ìˆ˜ ìˆëŠ” íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë‹¨ê³„
- Make a vectorstore: ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ & ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥
- Semantic search and document retrieving: ìœ ì €ì˜ ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•˜ê³  ì ì ˆí•œ Documentë¥¼ ë°˜í™˜í•˜ëŠ” ë‹¨ê³„
- Answer generation: ë°˜í™˜ëœ Documentë“¤ì„ contextë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ ìƒì„±



ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„  ì•ì„  ì„¸ ë‹¨ê³„ì— ëŒ€í•œ ì „ë°˜ì ì¸ ê°œë… ìœ„ì£¼ë¡œ ì„¤ëª…í•  ê²ƒì´ë©° ë‹¤ë£° ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

![vector_store_search](../images/2024-04-20-rag_1_loader_vectorstore/vector_store_search.jpg)

1. LangChainì˜ Document Loaderì— ëŒ€í•´ ì•Œì•„ë³¸ í›„ PDF loaderë¡œ pdf ìë£Œì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ Document í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ í›„
2. êµ¬ì„±ëœ Documentë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ VectorStoreì— ì €ì¥í•˜ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆí•œ Documentë“¤ì„ ë°˜í™˜í•˜ëŠ” ê²ƒê¹Œì§€ ì•Œì•„ë³¼ ì˜ˆì •ì´ë‹¤.



# Step1.  LangChainì˜ Document Loaderì— ëŒ€í•´ ì•Œì•„ë³´ê¸°

### Document Class

Document classëŠ” `langchain_core.documents`ì— ìœ„ì¹˜í•œ í´ë˜ìŠ¤ë¡œ ë­ì²´ì¸ì—ì„œ ë‹¤ë£¨ëŠ” ë¬¸ì„œ(documents)ì— ëŒ€í•œ ê°€ì¥ ê¸°ë³¸ì ì¸ í´ë˜ìŠ¤ì´ë‹¤. ì´ ë¬¸ì„œëŠ” ë‹¹ì—°í•˜ê²Œë„ í…ìŠ¤íŠ¸ë“¤ì˜ ì§‘í•©ì´ë©° ê·¸ëƒ¥ í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²ƒì´ ì•„ë‹Œ ë©”íƒ€ ë°ì´í„°ë¥¼ ê°™ì´ ë“¤ê³  ìˆì„ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì´ í´ë˜ìŠ¤ëŠ” í¬ê²Œ ë‘ê°€ì§€ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ ì ¸ìˆë‹¤.
- metadata(optional): dict ë°ì´í„° íƒ€ì…ìœ¼ë¡œ í•œ í˜ì´ì§€ì— ëŒ€í•œ ë©”íƒ€ ë°ì´í„°ë¥¼ ë‹´ê³  ìˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´ ì¶œì²˜, ë¬¸ì„œ ë‚´ í˜ì´ì§€ ë„˜ë²„, ë‹¤ë¥¸ ë¬¸ì„œë“¤ê³¼ì˜ ê´€ê³„ ë“±ì´ë‹¤.
- page_content: str íƒ€ì…ìœ¼ë¡œ ë¬¸ì„œê°€ ë‹´ê³  ìˆëŠ” ì»¨í…ì¸  ìì²´ì´ë‹¤.

ì˜ˆë¥¼ ë“¤ë©´ ì–´ëŠ í•œ ë…¼ë¬¸ì„ ê°€ì ¸ì™€ Documentë“¤ë¡œ êµ¬ì„±í•œë‹¤ê³  í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê¼´ì´ ë  ê²ƒì´ë‹¤.
| document_id | page_id | content_type  | text                                                               |
|-------------|---------|---------------|--------------------------------------------------------------------|
|     doc1    | 1       | ABSTRACT      | This paper presents a new framework to..                           |
|     doc2    | 1       | INTRODUCTION  | A floor plan is a drawing that describes..                         |
|     doc3    | 2       | RELATED_WORKS | Detecting and classifying floor-plan basic elements..              |
| ...         | ...     | ...           | ...                                                                |
|    doc100   | 17      | REFERENCES    | Kingma, D.P.; Ba, J. Adam: A method for stochastic optimization... |

ì´ í…Œì´ë¸”ì—ì„œ  `document_id`, `page_id`, `content_type`í•„ë“œë“¤ì€ metadataì— ë“¤ì–´ê°ˆ ê²ƒì´ë©° `text`í•„ë“œëŠ” page_contentê°€ ë  ê²ƒì´ë‹¤.

ë”°ë¼ì„œ documentì˜ metadataì™€ page_contentëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¼´ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.
```py
doc.metadata = {
    "document_id": "doc1",
    "page_id": 1,
    "content_type": "ABSTRACT"
}

doc.page_content = "This paper presents a new framework to classify floor plan elements and represent them in a vector format. Unlike existing approaches using image-based learning frameworks as the first step to segment the image pixels, we first convert the input floor plan image into vector data and utilize a graph neural network. Our framework consists of three steps."
```



### DocumentLoader

ê·¸ë ‡ë‹¤ë©´ ìœ„ì˜ Documentë¥¼ ìƒì„±í•´ë³´ì. LangChainì˜ êµ¬ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤‘ í•˜ë‚˜ì¸ langchain_communityì—” `document_loaders`ë€ í´ë”ê°€ ìˆë‹¤. ì—¬ê¸°ì—” ì—¬ëŸ¬ ê°€ì§€ í˜•íƒœì˜ Document Loaderë“¤ì´ ì •ì˜ ë¼ìˆìœ¼ë©° ë¬¸ì„œì˜ íƒ€ì…ì´ë‚˜ í¬ë§·ì— ë”°ë¼ ê±°ê¸°ì— ë§ëŠ” ë¯¸ë¦¬ êµ¬ì„±ëœ loaderë“¤ì„ ì‚¬ìš©í•˜ë©´ ëœë‹¤. 

ëª¨ë“  loaderë“¤ì€ `BaseLoader`ë¼ëŠ” í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„ë¼ìˆë‹¤. `BaseLoader`([ğŸ”—](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/document_loaders/base.py))ëŠ” `load()`ë¼ëŠ” ë©”ì„œë“œë¡œ documentë¥¼ ê°€ì ¸ì™€ `List[Document]`í˜•íƒœë¡œ ë°˜í™˜í•œë‹¤. 
    - `load_and_split` ë©”ì„œë“œëŠ” `RecursiveCharacterTextSplitter`ë¥¼ ì‚¬ìš©í•´ loadí•œ ê¸´ ë¬¸ì„œë¥¼ ì—¬ëŸ¬ ê°œì˜ chunkë“¤ë¡œ ë‚˜ëˆ  ë°˜í™˜í•œë‹¤(ê·¼ë° deprecateë  ì˜ˆì •ì´ë‹ˆ overrideí•˜ì§€ ë§ë¼ê³  ì¨ìˆë‹¤). chunkì— ëŒ€í•´ì„  ì•„ë˜ì—ì„œ ë” ìì„¸íˆ ì„¤ëª…í•  ì˜ˆì •ì´ë‹¤.

ì ê·¸ëŸ¼ ìš°ì„  ê°€ì¥ ê¸°ë³¸ì ì¸ TextLoaderë¥¼ ì‚¬ìš©í•´ì„œ ì˜ˆì‹œë¡œ ì‚¬ìš©ë  ë…¼ë¬¸ì˜ ì´ˆë¡ txt íŒŒì¼ì„ ê°€ì ¸ì™€ë³´ì.
íŒŒì¼ ê²½ë¡œë¥¼ ì¸ìë¡œ `TextLoader` ê°ì²´ë¥¼ í•˜ë‚˜ ë§Œë“¤ê³  `load()`ë¡œ `Document` ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.


```python
from langchain_community.document_loaders import TextLoader

file_path = base_dir + "/data/document_loaders/abstract.txt"

text_loader = TextLoader(
    file_path=file_path
)

docs = text_loader.load()

print(f"â–¶ï¸ No. of Documents: {len(docs)} \n\nâ–¶ï¸ Content: \n{docs[0].page_content}")
```

    â–¶ï¸ No. of Documents: 1 
    
    â–¶ï¸ Content: 
    Abstract
    This paper presents a new framework to classify floor plan elements and represent them in a vector format. Unlike existing approaches using image-based learning frameworks as the first step to segment the image pixels, we first convert the input floor plan image into vector data and utilize a graph neural network. Our framework consists of three steps. (1) image pre-processing ...



ìœ„ ê²°ê³¼ë¥¼ ë³´ë©´ ë¬¸ì„œ ë¶„í• ì„ ì ìš©í•˜ì§€ ì•Šì•„ ë‹¨ í•˜ë‚˜ì˜ documentì— ëª¨ë“  ë‚´ìš©ì´ ë‹´ê²¨ì ¸ ìˆë‹¤. load_and_splitì„ ì ìš©í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ì´ `RecursiveCharacterTextSplitter`ê°€ ì ë‹¹í•œ ê¸¸ì´ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ  ë”°ë¡œ `Document`ì— ì €ì¥í›„ `Document` listë¥¼ ë°˜í™˜í•œë‹¤.


```python
docs = text_loader.load_and_split()
print(f"â–¶ï¸ No. of Documents: {len(docs)} \n\nâ–¶ï¸ Contents")
for idx, doc in enumerate(docs):
    print(f"â–¶ï¸ Doc {str(idx)}: {doc.page_content}\n")

```

    â–¶ï¸ No. of Documents: 2 
    
    â–¶ï¸ Contents
    â–¶ï¸ Doc 0: Abstract
    This paper presents a new framework to classify floor plan elements and represent them in a vector format. Unlike existing approaches using image-based learning frameworks as the first step to segment the image pixels, we first convert the input floor plan image into vector data and utilize a graph neural network. Our framework consists of three steps. (1) image pre-processing and vectorization of the floor plan image; (2) region adjacency graph conversion; and (3) the graph neural network on converted floor plan graphs. Our approach is able to capture different types of indoor elements including basic elements, such as walls, doors, and symbols, as well as spatial elements, ...
    
    â–¶ï¸ Doc 1: In this paper, we propose a framework that finds any kind of element in the floor plan without losing the shape information. It first vectorizes the input floor plan image as it is to maintain the shape of the original indoor elements and minimize the abstraction. The polygon vector set is then converted into a region adjacency graph. The graph is then fed to an inductive learning-based graph neural network (GNN), which is used to compare multiple floor plan graphs and perform node classification by analyzing inherent features and the relationships between the nodes. This allows the user to classify basic indoor elements (e.g., walls, windows, doors, etc.) and symbols, together with ...



### PDFíŒŒì¼ Loader

ì•ì„œ ë§í–ˆë“¯ì´ document_loaders ì—ëŠ” BaseLoaderë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„ëœ ë‹¤ì–‘í•œ ë¬¸ì„œì˜ íƒ€ì…ì´ë‚˜ í¬ë§·ì— ë”°ë¥¸ loaderë“¤ì´ êµ¬í˜„ë¼ìˆë‹¤. ê·¸ ì¤‘ PDF íŒŒì¼ì— ëŒ€í•œ loaderë„ ì—¬ëŸ¬ ê°€ì§€ ìˆë‹¤. `PyPDFLoader`ëŠ” pypdfë¥¼ ì‚¬ìš©í•´ PDF íŒŒì¼ì„ `Document` ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤€ë‹¤. í˜ì´ì§€ ë‹¨ìœ„ë¡œ chunkë¡œ ë°”ê¿”ì£¼ë©° í˜ì´ì§€ ìˆ«ìë¥¼ metadataë¡œ ë„£ì–´ì¤€ë‹¤ê³  í•œë‹¤.

>  ì´ loaderë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  ë¯¸ë¦¬ pypdf ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•œë‹¤.

ì•„ë˜ì™€ ê°™ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ë©´ ì˜ ë‚˜ì˜¤ê³  ìˆìœ¼ë©° í˜ì´ì§€ ìˆ«ìê°€ `metadata['page']`ì— ë“¤ì–´ìˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.


```python
from langchain_community.document_loaders import PyPDFLoader

pdf_loader = PyPDFLoader(
    file_path = base_dir + "/data/document_loaders/paper.pdf",
    extract_images = False
)

docs = pdf_loader.load()

print(f"â–¶ï¸ No. of Documents: {len(docs)} \n\nâ–¶ï¸ Contents")
for idx, doc in enumerate(docs):
    print(f"â–¶ï¸ Doc {str(idx)}: {doc.page_content[:100]}...\nâ€» Metadata: page = {doc.metadata["page"]}\n")
```

```tex
â–¶ï¸ No. of Documents: 17 

â–¶ï¸ Contents
â–¶ï¸ Doc 0:  International Journal of
Geo-Information
Article
Framework for Indoor Elements Classiï¬cation via In...
â€» Metadata: page = 0

â–¶ï¸ Doc 1: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 2 of 17
models may be essential for speciï¬c user purposes, such ...
â€» Metadata: page = 1

â–¶ï¸ Doc 2: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 3 of 17
objects, respectively, in ï¬‚oor plans with various drawin...
â€» Metadata: page = 2

â–¶ï¸ Doc 3: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 4 of 17
pixel line. Then, the ï¬‚oor plan graph is fed into a GNN ...
â€» Metadata: page = 3

...

â–¶ï¸ Doc 16: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 17 of 17
19. Hu, R.; Huang, Z.; Tang, Y.; van Kaick, O.; Zhang, ...
â€» Metadata: page = 16
```





# Step 2. Vectore Storeë¥¼ ì‚¬ìš©í•´ Document ë°ì´í„° => ë²¡í„° ë°ì´í„°ë¡œ ì„ë² ë”© í•˜ì—¬ ì €ì¥í•˜ê¸°
ìš°ë¦¬ëŠ” APIë¥¼ í†µí•´ LLM ëª¨ë¸ì„ ê°€ì ¸ì™€ í™œìš©í•˜ê³  ìˆìœ¼ë‚˜ ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ì— ëŒ€í•´ì„  LLM ëª¨ë¸ì€ ì•Œì§€ ëª»í•œë‹¤. ìš°ë¦¬ê°€ ê°€ì§„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LM ëª¨ë¸ì—ê²Œì„œ ì›í•˜ëŠ” ë‹µì„ ì–»ê¸° ìœ„í•´ì„  ë°ì´í„°ë¥¼ í•™ìŠµ ì‹œí‚¤ê±°ë‚˜ í”„ë¡¬í”„íŠ¸ì—ì„œ ì•Œë ¤ì¤˜ì•¼í•˜ëŠ”ë° í•™ìŠµ, ì¦‰ ìš°ë¦¬ì˜ ë°ì´í„°ë¡œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ê¸°ì—” í˜„ì‹¤ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ê°€ ë§ë‹¤.

ë”°ë¼ì„œ ìš°ë¦¬ê°€ ê°€ì§„ ì»¤ìŠ¤í…€ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ ê·¸ ë°ì´í„°ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ LMì´ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•´ì¤˜ì•¼ í•˜ë©° ì´ ê³¼ì •ì„ í”íˆ RAG(Retrieval Augmented Generation)ë¼ê³  í•œë‹¤.

ì»¤ìŠ¤í…€ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ (í…ìŠ¤íŠ¸ ë°ì´í„°ë§Œ ìˆì„ ê²½ìš°) ê·¸ëƒ¥ ê·¸ëŒ€ë¡œ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” ê²ƒì´ì§€ë§Œ LLM ëª¨ë¸ APIì—ëŠ” 



### ë²¡í„° ìŠ¤í† ì–´ ìƒì„± & ë¬¸ì„œ ì„ë² ë”©

Vector StoreëŠ” ë§ vectorë“¤ì„ ë‹´ê³  ìˆëŠ” ì €ì¥ì†Œë¡œ ë²¡í„° ë°ì´í„° ì €ì¥ê³¼ ë™ë°˜í•´ ì—¬ëŸ¬ ê´€ë ¨ ê¸°ëŠ¥ë“¤ì„ í¬í•¨í•œ í´ë˜ìŠ¤ì´ë‹¤.


```python
from langchain_openai import OpenAIEmbeddings
from langchain_core.vectorstores import VectorStore #Vector Storeë“¤ì˜ ë² ì´ìŠ¤ í´ë˜ìŠ¤
from langchain_core.documents import Document
from typing import List
from langchain_community.vectorstores import chroma, faiss

open_ai_embedding_model = OpenAIEmbeddings()

def get_vector_store(vector_store_model:VectorStore, documents:List[Document], embedding_model):
    return vector_store_model.from_documents(embedding = embedding_model, documents = documents)

# Chroma
vector_store_chroma = get_vector_store(
    vector_store_model = chroma.Chroma, 
    documents = docs, 
    embedding_model = open_ai_embedding_model
)

# FAISS
vector_store_faiss = get_vector_store(
    vector_store_model = faiss.FAISS, 
    documents = docs, 
    embedding_model = open_ai_embedding_model
)
```

ìœ„ ì½”ë“œë¥¼ í†µí•´ ì €ì¥ëœ ë¬¸ì„œë¥¼ ì§ì ‘ ì–´ë–¤ ëª¨ìŠµì¸ì§€ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 

- FAISSì˜ ê²½ìš° ì‹¤ì œ ë¬¸ì„œë“¤ì€ ë‹¤ìŒ êµ¬ì¡°ë¡œ ì €ì¥ë¼ìˆë‹¤.
  `index(int) <=> docstore_id(str) <=> document_value(documents.base.Document)`

í˜„ì¬ ìƒì„±í•œ `vector_store_faiss`ì˜ ê²½ìš° `pdf_loader`ë¡œ ìƒì„±í•œ ì´ 17ê°œì˜ ë¬¸ì„œë“¤(docs)ì´ ë“¤ì–´ê°€ ìˆê³  0~16ë²ˆì˜ indexì™€ ë§µí•‘ë˜ëŠ” `docstore_id`ë“¤ê³¼ ê·¸ê²ƒì„ í‚¤ë¡œ ê°€ì§€ê³  ìˆëŠ” ì‹¤ì œ `Document` ì¸ìŠ¤í„´ìŠ¤ë“¤ì´ ìˆë‹¤.

ìƒ˜í”Œë¡œ index: 11 ë¬¸ì„œë¥¼ ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

```python
idx_docstore_id = vector_store_faiss.index_to_docstore_id
sample_doc_store_id = idx_docstore_id[11]
doc = vector_store_faiss.docstore.search(sample_doc_store_id)

print(f"""
- index: {11}
- docstore_id: {sample_doc_store_id}
- doc_metadata: {doc.metadata}
- page_content: {doc.page_content[:200]}, ...
""")
```


    - index: 11
    - docstore_id: 83def28e-b433-46f8-85d5-a7343309ccc2
    - doc_metadata: {'source': '/Users/lymansong/Documents/GitHub/study/langchain_tutorial/data/document_loaders/paper.pdf', 'page': 11}
    - page_content: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 12 of 17
    easily ï¬nd the dominant features on unseen data, such as predicting whether it is spatial or
    non-spatial by looking at the area attribute.
    Table 1. Class-w, ...



## ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•˜ê¸°

ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë§Œë“  ì£¼ ì´ìœ ëŠ” ë‹¨ìˆœíˆ ë¬¸ì„œë“¤ì„ ì €ì¥í•˜ê¸° ìœ„í•¨ì´ ì•„ë‹ˆê³  ê²€ìƒ‰í•˜ê¸° ì¢‹ê²Œ ì €ì¥í•˜ê¸° ìœ„í•´ì„œì´ë‹¤. 

ê²€ìƒ‰í•˜ê¸° ì¢‹ê²Œ í•˜ê¸° ìœ„í•´ ìì—°ì–´ë¥¼ ì„ë² ë”©ë²¡í„°ë¡œ ë°”ê¿”ì¤€ ê²ƒì´ë©° ìš°ë¦¬ê°€ ì…ë ¥í•œ ê²€ìƒ‰ì–´ ì—­ì‹œ ì„ë² ë”© ë²¡í„°ë¡œ ë°”ê¾¼ ë’¤ ê²€ìƒ‰ ì„ë² ë”©ê³¼ ë²¡í„° ìŠ¤í† ì–´ ë‚´ ì €ì¥ëœ ì„ë² ë”© ë²¡í„°ë“¤ ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°, ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ê²Œ ë‚˜ì˜¨ ë²¡í„°ë“¤ê³¼ ê·¸ ë²¡í„°ë“¤ì˜ ì›ë˜ ìì—°ì–´ì˜ ëª¨ìŠµì„ ë°˜í™˜í•´ì£¼ëŠ” ê²ƒì´ ë²¡í„° ìŠ¤í† ì–´ì˜ ì£¼ ê¸°ëŠ¥ì´ë‹¤.

ê·¸ëŸ¼ ìœ„ì—ì„œ ë§Œë“  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•´ ìœ ì €ê°€ ë˜ì§„ ìƒ˜í”Œ ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë‚´ìš©ì„ ê°€ì§„ ë¬¸ì„œë¥¼ ë°˜í™˜í•´ë³´ì. ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ê²ƒì€ **ìœ ì‚¬ì„± ê²€ì‚¬ë¥¼ ìœ„í•´ ìœ ì €ê°€ ë˜ì§„ ì§ˆë¬¸ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ì„ë² ë”© ëª¨ë¸ì— ë„£ì„ ë•Œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©í•œ ì„ë² ë”© ëª¨ë¸ê³¼ ë™ì¼í•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼í•œë‹¤ëŠ” ì ì´ë‹¤.** 


```python
import numpy as np

# ê²€ìƒ‰ ëŒ€ìƒ ìƒ˜í”Œ ì§ˆë¬¸ ìƒì„±
user_input_query = 'What is the title of the paper?'
user_input_q_vector = np.array([open_ai_embedding_model.embed_query(user_input_query)], dtype=np.float32)

# ìƒ˜í”Œ ì¿¼ë¦¬ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œë¥¼ ê²€ìƒ‰ í›„ ë°˜í™˜(k=1)
result = vector_store_faiss.index.search(x = user_input_q_vector, k = 1)

print(result) #(score, index)

## ë°˜í™˜ëœ ê²°ê³¼ì˜ index ê°’ìœ¼ë¡œ docstore_idë¥¼ ì°¾ê³  docstore_idë¡œ doc ì°¾ê¸°
doc = vector_store_faiss.docstore.search(vector_store_faiss.index_to_docstore_id[result[1][0][0]])

print(f"""
Result >>
- index: {result[1][0][0]}
- score(distance): {result[0][0][0]}
- docstore_id: {vector_store_faiss.index_to_docstore_id[result[1][0][0]]}
- page_content: {doc.page_content[:200]}, ...
      """)
```

    (array([[0.5138505]], dtype=float32), array([[16]]))
    
    Result >>
    - index: 16
    - score(distance): 0.5138505101203918
    - docstore_id: ca3b4a73-eb04-49c3-8abb-08bc06fdd78a
    - page_content: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 17 of 17
    19. Hu, R.; Huang, Z.; Tang, Y.; van Kaick, O.; Zhang, H.; Huang, H. Graph2Plan: Learning Floorplan Generation from Layout
    Graphs. arXiv 2020 , arXiv:2004., ...



ê²°ê³¼ëŠ” 17ë²ˆì§¸ ë¬¸ì„œê°€ ë°˜í™˜ ëìœ¼ë©° ìŠ¤ì½”ì–´ëŠ” ì •ê·œí™”ëœ ë‘ ë²¡í„° ì‚¬ì´ì˜ ê±°ë¦¬ë¡œ ì•½ 0.514ê°€ ë‚˜ì™”ë‹¤. 

ì´ë²ˆì—” ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë½‘ì•„ë³´ì(k = 3). ì§ˆë¬¸ ë²¡í„°ì— ëŒ€í•œ ë°˜í™˜ë˜ëŠ” ê° ë²¡í„°ë“¤ê³¼ì˜ ê±°ë¦¬ë“¤ì„ `1 - x/sqrt(2)`ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ ê°™ì´ ë„£ì–´ì¤¬ë‹¤

> OpenAIëŠ” ë²¡í„°ë¥¼ ë°˜í™˜í•  ë•Œ unit normed, ì¦‰ ë²¡í„°ì˜ í¬ê¸°ë¥¼ ì •ê·œí™”í•´ ìµœëŒ€ 1(ë‹¨ìœ„ë²¡í„°)ë¡œ ë³€í™˜í•´ ë°˜í™˜í•œë‹¤. ìœ„ ì‹ì€ ë°˜í™˜ëœ ì •ê·œí™”ëœ ìœ í´ë¦¬ë“œ ê±°ë¦¬ì— ëŒ€í•œ ìœ ì‚¬ì„±ì„ ë‹¤ì‹œ í•œë²ˆ % ë‹¨ìœ„ë¡œ ì •ê·œí™” í•´ì£¼ëŠ” í•¨ìˆ˜ë¡œ ì •ê·œí™”ëœ ë²¡í„° ì‚¬ì´ì˜ ê±°ë¦¬ëŠ” 0ì´ ê°€ì¥ ê°€ê¹Œìš´ ê²ƒ, sqrt(2)ê°€ ê°€ì¥ ë¨¼ ê²ƒì´ê¸°ì— ì´ ë²”ìœ„ ë‚´ì—ì„œ ìœ ì‚¬ë„ë¡œ ë³€í™˜í•´ì£¼ëŠ” ê²ƒì´ë‹¤.


```python
import math 

def print_retrieved_doc(rank, idx, score, vs, doc):
    return f"""
- K: {rank}
- index: {idx}
- similiarity: {round(score*100, 1)}%
- docstore_id: {vs.index_to_docstore_id[idx]}
- page_content: {doc.page_content[:200]}, ...
"""

def get_doc(idx, vs = vector_store_faiss):
    return vs.docstore.search(vs.index_to_docstore_id[idx])

get_relevance = lambda x: 1.0 - x / math.sqrt(2)

user_input_query = 'How to make a Region Adjacency Graph?'
user_input_q_vector = np.array([open_ai_embedding_model.embed_query(user_input_query)], dtype=np.float32)

results = vector_store_faiss.index.search(x = user_input_q_vector, k = 3)
print(results) #(score, index)

scores, doc_ids = results[0][0], results[1][0]

for doc_rank, (s, idx, doc) in enumerate(zip(map(get_relevance, scores), doc_ids, map(get_doc, doc_ids))):
    print(print_retrieved_doc(doc_rank, idx, s, vector_store_faiss, doc))

```

    (array([[0.37418255, 0.40982437, 0.4281325 ]], dtype=float32), array([[4, 5, 3]]))
    
    - K: 0
    - index: 4
    - similiarity: 73.5%
    - docstore_id: c4c6f979-8c38-49db-9972-aa89e966b0f8
    - page_content: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 5 of 17
    The detailed process is described as follows. A closed area surrounded by black pixels
    in the image becomes a polygon object. Likewise, a set of polygons is, ...
    
    - K: 1
    - index: 5
    - similiarity: 71.0%
    - docstore_id: 8a49da4b-0df8-46d3-8f30-0777d286a74f
    - page_content: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 6 of 17
    Algorithm 1: RAG conversion
    input : A polygon set P, a minimum area parameter m
    output : A ï¬‚oor plan graph G
    // Create a graph with adding polygon nodes
    1Gâ†, ...
    
    - K: 2
    - index: 3
    - similiarity: 69.7%
    - docstore_id: ad172925-4675-4901-8df2-9537ddc0c427
    - page_content: ISPRS Int. J. Geo-Inf. 2021 ,10, 97 4 of 17
    pixel line. Then, the ï¬‚oor plan graph is fed into a GNN model as the input graph and a
    graph is obtained where the nodes were classiï¬ed according to their l, ...



ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œ ì´ì–´ì„œ `Document` í…ìŠ¤íŠ¸ë¥¼ ê³ ì •ëœ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„ë¦¬í•´ì„œ ë²¡í„° ìŠ¤í† ì–´ì— ë„£ëŠ” ë°©ë²•, ê·¸ë¦¬ê³  ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ LLM ëª¨ë¸ì„ í†µí•´ ìœ ì €ì—ê²Œ ìì—°ì–´ë¡œ ìš”ì•½í•´ ì„¤ëª…í•˜ëŠ” Chainì„ êµ¬ì„±í•´ ë³¼ ì˜ˆì •ì´ë‹¤.



> ì°¸ê³  ë¬¸ì„œ ë° ë§í¬

- ì˜ˆì œ ë…¼ë¬¸ ë°ì´í„°: Song J, Yu K. Framework for Indoor Elements Classification via Inductive Learning on Floor Plan Graphs. *ISPRS International Journal of Geo-Information*. 2021; 10(2):97. [[ğŸ”—](Song J, Yu K. Framework for Indoor Elements Classification via Inductive Learning on Floor Plan Graphs. *ISPRS International Journal of Geo-Information*. 2021; 10(2):97. https://doi.org/10.3390/ijgi10020097)]
- LangChain API Reference [[ğŸ”—](https://api.python.langchain.com/en/latest/langchain_api_reference.html)]
- LangChain Docs > Components > Retrieval [[ğŸ”—](https://python.langchain.com/docs/modules/data_connection/)]
